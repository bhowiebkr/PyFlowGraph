---
id: "3.2"
title: "Single Shared Python Interpreter"
type: "Feature"
priority: "High"
status: "Draft"
assigned_agent: "dev"
epic_id: "3"
sprint_id: ""
created_date: "2025-01-20"
updated_date: "2025-01-20"
estimated_effort: "XL"
dependencies: ["3.1 - Basic Group Creation and Selection"]
tags: ["execution", "performance", "architecture", "subprocess-replacement"]

user_type: "Developer"
component_area: "Execution Engine"
technical_complexity: "High"
business_value: "High"
---

# Story 3.2: Single Shared Python Interpreter

## Story Description

**As a** developer, **I want** all nodes to execute in a single persistent Python interpreter, **so that** objects can be passed directly without any serialization or process boundaries.

### Context
This story transforms PyFlowGraph's execution architecture from isolated subprocess-per-node to a single shared Python interpreter, enabling direct object passing and achieving 100-1000x performance improvements for ML/data science workflows. This architectural change eliminates serialization overhead and enables true zero-copy object sharing between nodes.

### Background
The current GraphExecutor uses subprocess.run() for each node execution, creating significant overhead through:
- Process creation/destruction costs
- JSON serialization/deserialization of all data
- Loss of object references between nodes
- Inability to share complex objects like PyTorch tensors, DataFrames

This story replaces the subprocess model with direct Python function calls in a shared interpreter, maintaining the same interface while delivering massive performance gains.

## Acceptance Criteria

### AC1: Single Python interpreter shared across all node executions
**Given** multiple nodes in a graph  
**When** nodes are executed  
**Then** all nodes execute in the same Python interpreter process

### AC2: Persistent namespace allowing imports and variables to remain loaded
**Given** a node imports a library or defines variables  
**When** subsequent nodes execute  
**Then** imported libraries and variables remain available without re-import

### AC3: Direct function calls replacing subprocess communication
**Given** a node function is ready for execution  
**When** the node executes  
**Then** the function is called directly without subprocess creation

### AC4: Shared memory space for all Python objects
**Given** nodes that pass large objects between each other  
**When** execution occurs  
**Then** objects are passed by reference without copying or serialization

### AC5: Zero startup overhead between node executions
**Given** sequential node executions in a graph  
**When** nodes execute one after another  
**Then** there is no process startup time between executions

## Tasks / Subtasks

### Implementation Tasks
- [ ] **Task 1**: Replace subprocess execution with direct function calls (AC: 1, 3)
  - [ ] Subtask 1.1: Create SingleProcessExecutor class replacing subprocess calls
  - [ ] Subtask 1.2: Modify _execute_node_flow to call functions directly
  - [ ] Subtask 1.3: Remove subprocess.run() and JSON serialization logic
  - [ ] Subtask 1.4: Implement direct Python function invocation

- [ ] **Task 2**: Implement persistent interpreter namespace (AC: 2)
  - [ ] Subtask 2.1: Create shared global namespace for all node executions
  - [ ] Subtask 2.2: Preserve imports and variables between node executions
  - [ ] Subtask 2.3: Add namespace management and cleanup capabilities
  - [ ] Subtask 2.4: Handle variable naming conflicts and scoping

- [ ] **Task 3**: Implement direct object passing system (AC: 4)
  - [ ] Subtask 3.1: Replace JSON serialization with direct object references
  - [ ] Subtask 3.2: Modify pin_values dictionary to store actual Python objects
  - [ ] Subtask 3.3: Support all Python types including NumPy arrays, tensors, DataFrames
  - [ ] Subtask 3.4: Implement reference counting for memory management

- [ ] **Task 4**: Optimize execution performance (AC: 5)
  - [ ] Subtask 4.1: Remove process creation overhead completely
  - [ ] Subtask 4.2: Eliminate JSON serialization/deserialization delays
  - [ ] Subtask 4.3: Implement zero-copy object sharing
  - [ ] Subtask 4.4: Add performance timing and benchmarking

- [ ] **Task 5**: Maintain execution error handling and logging (AC: 1-5)
  - [ ] Subtask 5.1: Implement try/catch around direct function calls
  - [ ] Subtask 5.2: Capture stdout/stderr from direct execution
  - [ ] Subtask 5.3: Maintain existing error reporting format
  - [ ] Subtask 5.4: Add debugging capabilities for shared interpreter

- [ ] **Task 6**: Update ExecutionController integration (AC: 1, 3)
  - [ ] Subtask 6.1: Modify ExecutionController to use SingleProcessExecutor
  - [ ] Subtask 6.2: Update execution interface to maintain compatibility
  - [ ] Subtask 6.3: Preserve existing execution flow control logic
  - [ ] Subtask 6.4: Maintain event system integration

### Testing Tasks
- [ ] **Task 7**: Create unit tests for single process execution (AC: 1, 3, 5)
  - [ ] Test direct function call execution vs subprocess
  - [ ] Test execution performance improvements
  - [ ] Test error handling in direct execution mode
  - [ ] Test stdout/stderr capture from direct calls

- [ ] **Task 8**: Create integration tests for object passing (AC: 2, 4)
  - [ ] Test persistent namespace across multiple node executions
  - [ ] Test direct object passing without serialization
  - [ ] Test complex object types (tensors, DataFrames, custom classes)
  - [ ] Test variable persistence and import sharing

- [ ] **Task 9**: Add performance benchmark tests (AC: 5)
  - [ ] Create benchmark comparing subprocess vs direct execution
  - [ ] Test memory usage improvements
  - [ ] Test execution speed improvements for ML workflows
  - [ ] Validate 100-1000x performance improvement claims

### Documentation Tasks
- [ ] **Task 10**: Update architecture documentation
  - [ ] Document new single process execution model
  - [ ] Update performance characteristics and capabilities
  - [ ] Add migration notes for existing graphs

## Dev Notes

### Previous Story Insights
Key learnings from Story 3.1 (Basic Group Creation):
- Command pattern integration provides solid foundation for complex operations
- Qt QGraphicsItem architecture handles container-style objects well
- UUID-based object tracking provides reliable reference management
- Testing infrastructure requires careful setup for Qt-based components
[Source: docs/stories/3.1.story.md#post-qa-resolution-status]

### Current Execution Architecture
The current GraphExecutor uses subprocess isolation for security:
- **Subprocess Model**: Each node execution creates new Python subprocess via subprocess.run()
- **Communication**: JSON serialization for all data transfer between processes
- **Isolation**: Complete process isolation prevents variable sharing
- **Performance Overhead**: Process creation + JSON serialization creates significant delays
- **Security Trade-off**: Isolation provides security but eliminates performance benefits
[Source: src/execution/graph_executor.py lines 74-174]

### Technical Implementation Details

#### Execution System Integration Points
- **GraphExecutor Class**: Located in `src/execution/graph_executor.py` - Main execution orchestrator
- **Current Flow**: `execute()` -> `_execute_node_flow()` -> subprocess.run() for each node
- **JSON Communication**: Input/output data serialized as JSON strings
- **Error Handling**: subprocess stderr/stdout captured and logged
- **Virtual Environment**: Python executable path resolved via `get_python_executable()`
[Source: src/execution/graph_executor.py lines 36-72, 74-174]

#### File Locations & Structure
- **Main Executor**: `src/execution/graph_executor.py` - Replace subprocess calls with direct execution
- **New Single Process Executor**: `src/execution/single_process_executor.py` - Create direct execution class
- **Controller Integration**: `src/execution/execution_controller.py` - Update to use new executor
- **Test Files**: `tests/test_single_process_execution.py` (new), extend existing execution tests
[Source: docs/architecture/source-tree.md#execution-system]

#### Data Flow Architecture
- **Current Pin Values**: Dictionary mapping Pin objects to JSON-serializable values
- **New Object References**: Dictionary mapping Pin objects to actual Python objects
- **Memory Management**: Direct object references require careful cleanup
- **Type Support**: Must handle all Python types without JSON limitations
[Source: src/execution/graph_executor.py lines 88-95, 125-140]

#### Performance Considerations
- **Subprocess Overhead**: Current model creates ~50-200ms overhead per node execution
- **JSON Serialization**: Large objects (DataFrames, tensors) have significant serialization cost
- **Memory Copying**: Current model copies all data between processes
- **Target Performance**: Direct execution should achieve <1ms overhead per node
[Source: docs/prd.md#non-functional-requirements]

#### Security Implications
- **Current Security**: Process isolation prevents code from affecting main application
- **New Security Model**: All code executes in main process - requires careful error handling
- **Risk Mitigation**: Comprehensive exception handling and namespace management
- **Trade-off**: Performance gains vs reduced isolation security
[Source: docs/architecture/tech-stack.md#security-considerations]

### Testing Requirements

#### Test File Locations
- **Unit Tests**: `tests/test_single_process_execution.py` (new) - Direct execution testing
- **Integration Tests**: Extend existing `tests/test_execution_engine.py` for new executor
- **Performance Tests**: `tests/test_execution_performance.py` (new) - Benchmark comparisons
- **Test Naming**: Follow `test_{behavior}_when_{condition}` pattern
[Source: docs/architecture/coding-standards.md#testing-standards]

#### Testing Framework and Patterns
- **Framework**: Python unittest (established pattern in project)  
- **Test Runner**: Custom PySide6 GUI test runner for interactive testing
- **Timeout**: All tests must complete within 10 seconds maximum
- **Performance Focus**: Benchmark tests comparing subprocess vs direct execution
[Source: docs/architecture/tech-stack.md#testing-framework, CLAUDE.md#testing]

#### Specific Testing Requirements
- Test direct function call execution replacing subprocess.run()
- Test persistent namespace and variable sharing between executions
- Test direct object passing without JSON serialization
- Test error handling and exception propagation in direct execution
- Test stdout/stderr capture from direct function calls
- Test memory management and object cleanup
- Test performance improvements with benchmark comparisons
- Test compatibility with existing execution flow and event systems

### Technical Constraints
- **Windows Platform**: Use Windows-compatible commands and paths, no Unicode characters
- **PySide6 Framework**: Maintain compatibility with existing Qt-based architecture
- **Existing Patterns**: Preserve GraphExecutor interface and ExecutionController integration
- **Backward Compatibility**: Existing graphs must work without modification
[Source: docs/architecture/coding-standards.md#prohibited-practices, CLAUDE.md]

## Change Log

| Date       | Version | Description                 | Author    |
| ---------- | ------- | --------------------------- | --------- |
| 2025-01-20 | 1.0     | Initial story creation based on PRD Epic 3 | Bob (SM) |